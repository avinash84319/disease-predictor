{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_notp.csv')\n",
    "\n",
    "# Convert string labels to numerical labels\n",
    "label_encoder = LabelEncoder()\n",
    "df['Disease_ID'] = label_encoder.fit_transform(df['Disease_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_data['Patient_Description'])\n",
    "total_words = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = tokenizer.texts_to_sequences(train_data['Patient_Description'])\n",
    "test_sequences = tokenizer.texts_to_sequences(test_data['Patient_Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_padded_sequences = pad_sequences(train_sequences)\n",
    "test_padded_sequences = pad_sequences(test_sequences, maxlen=train_padded_sequences.shape[1])\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "train_labels = tf.keras.utils.to_categorical(train_data['Disease_ID'], num_classes=len(set(df['Disease_ID'])))\n",
    "test_labels = tf.keras.utils.to_categorical(test_data['Disease_ID'], num_classes=len(set(df['Disease_ID'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_padded_sequences.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 64, input_length=train_padded_sequences.shape[1]))\n",
    "model.add(LSTM(100))\n",
    "model.add(tf.keras.layers.Dense(256))\n",
    "model.add(tf.keras.layers.Dense(128))\n",
    "model.add(Dense(len(set(df['Disease_ID'])), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2200/2200 [==============================] - 66s 30ms/step - loss: 0.8278 - accuracy: 0.5834 - val_loss: 0.8676 - val_accuracy: 0.5808\n",
      "Epoch 2/5\n",
      "2200/2200 [==============================] - 66s 30ms/step - loss: 0.8294 - accuracy: 0.5777 - val_loss: 0.8109 - val_accuracy: 0.5850\n",
      "Epoch 3/5\n",
      "2200/2200 [==============================] - 68s 31ms/step - loss: 0.8198 - accuracy: 0.5814 - val_loss: 0.8073 - val_accuracy: 0.5863\n",
      "Epoch 4/5\n",
      "2200/2200 [==============================] - 66s 30ms/step - loss: 0.8104 - accuracy: 0.5857 - val_loss: 0.8089 - val_accuracy: 0.5841\n",
      "Epoch 5/5\n",
      "2200/2200 [==============================] - 66s 30ms/step - loss: 0.8113 - accuracy: 0.5831 - val_loss: 0.7967 - val_accuracy: 0.5818\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12585583590>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_padded_sequences, train_labels, epochs=5, verbose=1, validation_data=(test_padded_sequences, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_queries = [\"I have Sneezing, Runny recently. The Runny is a bit troublesome. It's a bit inconvenient but not too disruptive to my daily activities. I've had similar issues in the past but never this persistent..\", \"I have Chest, Wheezing, Shortness in the last few days. The Wheezing is a bit bothersome. It's a bit inconvenient but not too disruptive to my daily activities. I haven't seen a doctor yet, but I'm keeping an eye on the symptoms..\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "Predicted Classes: [18, 28]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize and pad new queries\n",
    "new_sequences = tokenizer.texts_to_sequences(new_queries)\n",
    "new_padded_sequences = pad_sequences(new_sequences, maxlen=train_padded_sequences.shape[1])\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(new_padded_sequences)\n",
    "\n",
    "# Convert predicted numerical classes back to original string values\n",
    "predicted_classes = [label_encoder.classes_[tf.argmax(prediction).numpy()] for prediction in predictions]\n",
    "print(\"Predicted Classes:\", predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"disease_notp.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('disease_tokenizer_notp.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('disease_label_encoder_notp.pickle', 'wb') as handle:\n",
    "    pickle.dump(label_encoder, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
